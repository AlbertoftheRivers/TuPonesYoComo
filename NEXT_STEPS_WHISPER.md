# PrÃ³ximos Pasos - Whisper Instalado

## âœ… Lo que ya estÃ¡ hecho:
- Whisper Python instalado
- Modelo `base` descargado
- Backend actualizado con endpoint `/api/transcribe`
- `multer` instalado para manejar uploads de audio

## Paso 1: Reiniciar el servicio del backend

```bash
# Reiniciar el servicio para cargar los cambios
sudo systemctl restart tuponesyocomo-api

# Verificar que estÃ¡ funcionando
sudo systemctl status tuponesyocomo-api

# Ver logs en tiempo real
sudo journalctl -u tuponesyocomo-api -f
```

DeberÃ­as ver en los logs:
```
ğŸš€ Backend API server running on port 3000
ğŸ“¡ Ollama URL: http://192.168.200.45:11434
ğŸ¤– Ollama Model: llama3.2:3b
ğŸ¤ Whisper Model: base
ğŸŒ Health check: http://localhost:3000/health
```

## Paso 2: Verificar el endpoint de salud

```bash
# Probar el endpoint de salud (deberÃ­a mostrar informaciÃ³n de Whisper)
curl http://localhost:3000/health
```

DeberÃ­as ver algo como:
```json
{
  "status": "ok",
  "ollama_url": "http://192.168.200.45:11434",
  "model": "llama3.2:3b",
  "whisper_model": "base",
  "whisper_venv": "/opt/apps/TuPonesYoComo/backend/whisper_venv"
}
```

## Paso 3: Probar el endpoint de transcripciÃ³n (opcional)

Si tienes un archivo de audio de prueba:

```bash
# Probar transcripciÃ³n
curl -X POST http://localhost:3000/api/transcribe \
  -F "audio=@/ruta/a/tu/audio.m4a" \
  -F "language=es"
```

## Paso 4: Continuar con el frontend

Ahora necesitamos:
1. Agregar botÃ³n de micrÃ³fono en `AddRecipeScreen` y `EditRecipeScreen`
2. Implementar grabaciÃ³n de audio con `expo-av`
3. Enviar audio al backend para transcripciÃ³n
4. Insertar texto transcrito en el campo `raw_text`

Â¿Listo para continuar con el frontend?

